{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install pandas and geopandas libraries, if required\n",
    "# !pip install pandas geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list with element names from OIM specification\n",
    "oim_specification_element_names = [\n",
    "    'available',\n",
    "    'bathInterv',\n",
    "    'bathLines',\n",
    "    'color',\n",
    "    'contInterv',\n",
    "    'contLines',\n",
    "    'date',\n",
    "    'datePhoto',\n",
    "    'datePub',\n",
    "    'dateReprnt',\n",
    "    'dateSurvey',\n",
    "    'digHold',\n",
    "    'download',\n",
    "    'edition',\n",
    "    'fileName',\n",
    "    'geometry',\n",
    "    'iiifUrl',\n",
    "    'inst',\n",
    "    'instCallNo',\n",
    "    'label',\n",
    "    'labelAlt',\n",
    "    'labelAlt2',\n",
    "    'lcCallNo',\n",
    "    'location',\n",
    "    'note',\n",
    "    'overlays',\n",
    "    'overprint',\n",
    "    'physHold',\n",
    "    'primeMer',\n",
    "    'projection',\n",
    "    'publisher',\n",
    "    'recId',\n",
    "    'scale',\n",
    "    'sheetId',\n",
    "    'thumbUrl',\n",
    "    'title',\n",
    "    'titleAlt',\n",
    "    'websiteUrl'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list contains fields with a boolean data type, and is used later to check whether these fields contain null values\n",
    "# Update, as needed\n",
    "boolean_field_names = [\n",
    "    'available',\n",
    "    'bathLines',\n",
    "    'contLines'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping for incorrect element names\n",
    "# These key-value pairs represent incorrect title names encountered to date; they are not exhaustive\n",
    "# Later cells will incorporate additional pairs into the script for future executions; it is not necessary to manually update this dictionary\n",
    "# Incorrect names are on the left (dictionary keys); correct names are on the right (dictionary values)\n",
    "element_name_mappings = dict(\n",
    "    # incorrectName = 'correctName'\n",
    "    notes = 'note',\n",
    "    lcCall = 'lcCallNo',\n",
    "    instCall = 'instCallNo',\n",
    "    iiifURL = 'iiifUrl',\n",
    "    year = 'date',\n",
    "    sheetID = 'sheetId',\n",
    "    digHolding = 'digHold',\n",
    "    avaliable = 'available',\n",
    "    contInt = 'contInterv',\n",
    "    bathInt ='bathInterv',\n",
    "    dateReprint = 'dateReprnt',\n",
    "    editionNotes = 'note_ed' # This is a temporary name that is needed to differentiate the field from the 'note' field to combine the two later\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for reading GeoJSON file\n",
    "# Returns a GeoDataFrame\n",
    "def read_geojson_file(geojson_file):\n",
    "    return gpd.read_file(geojson_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to replace default null values (np.nan) with pd.NA\n",
    "# Changes dtype of columns with nulls from 'float' to 'object'\n",
    "# Assists with string operations for entire dataframe (e.g., removing white space)\n",
    "def fill_nulls_with_pandas_NA(geodataframe):\n",
    "    return geodataframe.fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that returns element names that do not match OIM specification\n",
    "def get_incorrect_element_names(geodataframe):\n",
    "    element_names_matching_specification = pd.Series(geodataframe.columns).isin(oim_specification_element_names)\n",
    "    return pd.Series(geodataframe.columns)[~element_names_matching_specification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that returns incorrect element names not already included in the element_name_mappings dictionary\n",
    "def incorrect_element_names_unaccounted_for(series):\n",
    "    element_names_accounted_for = series.isin(element_name_mappings.keys())\n",
    "    return series[~element_names_accounted_for]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function which returns incorrect element names not already included in element_name_mappings dictionary\n",
    "# and asks the user to input correct names\n",
    "# These incorrect name: correct name key-value pairs are added to the element_name_mappings dictionary\n",
    "def update_element_name_mappings_dictionary(series_of_element_names_unaccounted_for, dictionary_mapping):\n",
    "    if len(series_of_element_names_unaccounted_for) > 0:\n",
    "        for element in series_of_element_names_unaccounted_for:\n",
    "            user_inputted_element_name = input(f'\\nThe following element name does not match the OIM specification:\\n\\n{element}\\n\\nWhat would you like to replace it with? ')\n",
    "            dictionary_mapping[element] = user_inputted_element_name\n",
    "        with open(os.path.join(os.path.dirname(os.getcwd()), 'element_name_mappings_python_dictionary.txt'), 'wb') as file:\n",
    "            pickle.dump(dictionary_mapping, file)\n",
    "        with open(os.path.join(os.path.dirname(os.getcwd()), 'element_name_mappings_python_dictionary.txt'), 'rb') as file:\n",
    "            dictionary_mapping = pickle.load(file)\n",
    "        return dictionary_mapping\n",
    "    return dictionary_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that replaces incorrect element names with correct ones\n",
    "def replace_incorrect_element_names(geodataframe, dictionary_mapping):\n",
    "    geodataframe.columns = [dictionary_mapping[element_name] if element_name in dictionary_mapping.keys() else element_name for element_name in geodataframe.columns]\n",
    "    return geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function which handles 'note' fields\n",
    "def handle_note_fields(geodataframe):\n",
    "    if 'note' in geodataframe.columns and 'note_ed' in geodataframe.columns:\n",
    "        geodataframe['note'] = geodataframe['note'].fillna('') + '; ' + geodataframe['note_ed'].fillna('')\n",
    "        geodataframe['note'] = geodataframe['note'].str.strip('; ')\n",
    "        geodataframe['note'] = geodataframe['note'].replace('', pd.NA)\n",
    "        geodataframe = geodataframe.drop(columns = 'note_ed')\n",
    "    elif 'note' not in geodataframe.columns and 'note_ed' in geodataframe.columns:\n",
    "        geodataframe = geodataframe.rename(columns = {'note_ed': 'note'})\n",
    "    return geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to combine values of duplicate fields into single field\n",
    "# E.g., file containing values in both 'lcCallNo' and 'lcCall' fields are transferred into 'lcCallNo' field\n",
    "def combine_values_of_fields_with_same_name(geodataframe):\n",
    "    boolean_series_of_fields_with_multiple_columns = pd.Series(geodataframe.columns).value_counts() > 1\n",
    "    fields_with_multiple_columns = boolean_series_of_fields_with_multiple_columns[boolean_series_of_fields_with_multiple_columns].index\n",
    "    for name in fields_with_multiple_columns:\n",
    "        multiple_columns_df = geodataframe[name]\n",
    "        multiple_columns_df.columns = list(range(0, len(geodataframe[name].columns)))\n",
    "        multiple_columns_df = multiple_columns_df.apply(lambda x: x.fillna(''))\n",
    "        combined_column = multiple_columns_df.apply(lambda row: ''.join(row.values.astype(str)), axis = 1)\n",
    "        combined_column = combined_column.replace('', pd.NA)\n",
    "        geodataframe = geodataframe.drop(columns = name)\n",
    "        geodataframe[name] = combined_column\n",
    "    return geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check whether boolean fields contain null values\n",
    "def nulls_in_boolean_fields(geodataframe, file_name):\n",
    "    for field_name in boolean_field_names:\n",
    "        if field_name in geodataframe.columns and geodataframe[field_name].isnull().any():\n",
    "            user_input = input(f\"\\nThe following boolean field in {file_name} contains null values:\\n\\n{field_name}\\n\\nWould you like to convert these to 'false'? ('y' or 'n'; 'n' will leave values as null) \").lower()\n",
    "            if user_input in ['y', 'yes']:\n",
    "                geodataframe[field_name] = geodataframe[field_name].fillna('false')\n",
    "            elif user_input in ['n', 'no']:\n",
    "                geodataframe[field_name] = geodataframe[field_name]\n",
    "            else:\n",
    "                second_input = input(\"\\nYou entered an invalid option. Please enter either 'y' for 'yes' or 'n' for 'no'. \")\n",
    "                if second_input in ['y', 'yes']:\n",
    "                    geodataframe[field_name] = geodataframe[field_name].fillna('false')\n",
    "                else:\n",
    "                    geodataframe[field_name] = geodataframe[field_name]\n",
    "    return geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert values of boolean fields to 'true'/'false' strings\n",
    "def convert_boolean_values_to_true_false_strings(geodataframe):\n",
    "    for field_name in boolean_field_names:\n",
    "        if field_name in geodataframe.columns:\n",
    "            geodataframe[field_name] = geodataframe[field_name].astype('string').str.lower()\n",
    "    return geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove extra white space\n",
    "def remove_extra_white_space(geodataframe):\n",
    "    return geodataframe.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove invalid data structures (e.g., lists)\n",
    "# This is necessary for geopandas to write to GeoJSON\n",
    "def remove_invalid_data_structures(geodataframe):\n",
    "    for field_name in geodataframe.columns:\n",
    "        if geodataframe[field_name].apply(lambda x: isinstance(x, list)).any():\n",
    "            geodataframe = geodataframe.explode(field_name)\n",
    "    return geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to write processed GeoJSON file back to original directory\n",
    "def write_geojson_file(geodataframe, file_name):\n",
    "    geodataframe = geodataframe.set_geometry(col = 'geometry')\n",
    "    geodataframe.to_file(file_name, driver = 'GeoJSON')\n",
    "    return print(f'Writing {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing china_250k_L500.geojson\n",
      "Writing china_250k_L500.geojson\n",
      "Processing china_250k_L531.geojson\n",
      "Writing china_250k_L531.geojson\n",
      "Processing china_250k_L532.geojson\n",
      "Writing china_250k_L532.geojson\n",
      "Processing china_250k_L542.geojson\n",
      "Writing china_250k_L542.geojson\n",
      "Processing china_250k_L581.geojson\n",
      "Writing china_250k_L581.geojson\n",
      "Processing china_250k_L582.geojson\n",
      "Writing china_250k_L582.geojson\n",
      "Processing indonesia_250k.geojson\n",
      "Writing indonesia_250k.geojson\n",
      "Processing philippines_250k.geojson\n",
      "Writing philippines_250k.geojson\n",
      "Processing france_250k.geojson\n",
      "Writing france_250k.geojson\n",
      "Processing france_500k.geojson\n",
      "Writing france_500k.geojson\n",
      "Processing iceland_250k.geojson\n",
      "Writing iceland_250k.geojson\n",
      "Processing canada_250k_nts.geojson\n",
      "Writing canada_250k_nts.geojson\n",
      "Processing canada_25k_nts.geojson\n",
      "Writing canada_25k_nts.geojson\n",
      "Processing canada_500k_nts.geojson\n",
      "Writing canada_500k_nts.geojson\n",
      "Processing canada_50k_nts.geojson\n",
      "Writing canada_50k_nts.geojson\n",
      "Processing canada_alberta_50k_nts.geojson\n",
      "Writing canada_alberta_50k_nts.geojson\n",
      "Processing canada_britishColumbia_50k_nts.geojson\n",
      "Writing canada_britishColumbia_50k_nts.geojson\n",
      "Processing canada_britishColumbia_columbiaRiverBasin_1958.geojson\n",
      "Writing canada_britishColumbia_columbiaRiverBasin_1958.geojson\n",
      "Processing canada_britishColumbia_gvrd.geojson\n",
      "Writing canada_britishColumbia_gvrd.geojson\n",
      "Processing canada_britishColumbia_ifcsm.geojson\n",
      "Writing canada_britishColumbia_ifcsm.geojson\n",
      "Processing canada_britishColumbia_ubc.geojson\n",
      "Writing canada_britishColumbia_ubc.geojson\n",
      "Processing canada_britishColumbia_yaletown.geojson\n",
      "Writing canada_britishColumbia_yaletown.geojson\n",
      "Processing canada_manitoba_50k_nts.geojson\n",
      "Writing canada_manitoba_50k_nts.geojson\n",
      "Processing canada_nonna_p10_files.geojson\n",
      "Writing canada_nonna_p10_files.geojson\n",
      "Processing canada_nonna_p10_packages.geojson\n",
      "Writing canada_nonna_p10_packages.geojson\n",
      "Processing canada_northwestTerritory_50k_nts.geojson\n",
      "Writing canada_northwestTerritory_50k_nts.geojson\n",
      "Processing canada_saskatchewan_50k_nts.geojson\n",
      "Writing canada_saskatchewan_50k_nts.geojson\n",
      "Processing canada_yukonTerritory_50k_nts.geojson\n",
      "Writing canada_yukonTerritory_50k_nts.geojson\n",
      "Processing mexico_250k_geological.geojson\n",
      "Writing mexico_250k_geological.geojson\n",
      "\n",
      "PROCESSING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Apply functions to process GeoJSONs within all directories\n",
    "list_of_continent_directories = [item for item in os.listdir() if '.' not in item]\n",
    "\n",
    "for directory in list_of_continent_directories:\n",
    "    os.chdir(directory)\n",
    "    for file in os.listdir():\n",
    "        if file.endswith('.geojson'):\n",
    "            print(f'Processing {file}')\n",
    "            gdf = read_geojson_file(file)\n",
    "            gdf = fill_nulls_with_pandas_NA(gdf)\n",
    "            incorrect_element_names = get_incorrect_element_names(gdf)\n",
    "            element_names_unaccounted_for = incorrect_element_names_unaccounted_for(incorrect_element_names)\n",
    "            element_name_mappings = update_element_name_mappings_dictionary(element_names_unaccounted_for, element_name_mappings)\n",
    "            gdf = replace_incorrect_element_names(gdf, element_name_mappings)\n",
    "            gdf = handle_note_fields(gdf)\n",
    "            gdf = combine_values_of_fields_with_same_name(gdf)\n",
    "            gdf = nulls_in_boolean_fields(gdf, file)\n",
    "            gdf = convert_boolean_values_to_true_false_strings(gdf)\n",
    "            gdf = remove_extra_white_space(gdf)\n",
    "            gdf = remove_invalid_data_structures(gdf)\n",
    "            write_geojson_file(gdf, file)\n",
    "    os.chdir('..')\n",
    "\n",
    "print('\\nPROCESSING COMPLETE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
